# Global MCP configuration
[llm]
model = "claude-3-5-sonnet"
base_url = "GitFish"
api_key = "GitFish-..."
max_tokens = 4096
temperature = 0

# [llm] #AZURE OPENAI:
# api_type= 'TEST'
# model = "YOUR_MODEL_NAME" #"Nore"
# base_url = "{YOUR_AZURE_ENDPOINT.rstrip('/')}/openai/deployments/{AZURE_DEPOLYMENT_ID}"  
# api_key = "Gt13Qv8crfZJ63v9mEUgacq48vyqoxEGLtRmMYiJJbpM"
# max_tokens = 8096
# temperature = 0.0
# api_version="AZURE API VERSION" #"2024-08-01-preview"

# Optional configuration for specific LLM models
[llm.vision]
model = "claude-3-5-sonnet"
base_url = "GitFish"
api_key = "Gt13Qv8crfZJ63v9mEUgacq48vyqoxEGLtRmMYiJJbpM"

